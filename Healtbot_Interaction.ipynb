{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeivq9N4psHR",
        "outputId": "c985aac7-0e72-461d-afb4-ce916e3b2701"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from nltk.chat.util import Chat, reflections\n",
        "import pickle\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizer\n",
        "import nltk\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0_KbSxEpLK8",
        "outputId": "088d3ccf-4234-491b-ceca-e24c9f775e47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "_ysoT9Z_p7yv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GX1XGn3cpLIq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/gdrive/MyDrive/healthbot/\"\n",
        "file_name = 'med_data_all.pkl'\n",
        "with open(path + file_name , 'rb') as file:\n",
        "    med_data = pickle.load(file)"
      ],
      "metadata": {
        "id": "1OOVL9yFPLMy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the knowledge graph\n",
        "path = \"/content/gdrive/MyDrive/healthbot/\"\n",
        "file_name = 'knowledge_graph.pkl'\n",
        "with open(path + file_name , 'rb') as file:\n",
        "    knowledge_graph = pickle.load(file)"
      ],
      "metadata": {
        "id": "c3EVR0RJOenP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(inp):\n",
        "  preprocessed_texts = []\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  for text in inp:\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    #remove stop words\n",
        "    #words = text.split()\n",
        "    #filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    #preprocessed_texts.append(' '.join(filtered_words))\n",
        "    preprocessed_texts.append(text)\n",
        "  return preprocessed_texts"
      ],
      "metadata": {
        "id": "Z15TK6VAPzDu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_texts = preprocess(med_data['inputs'])\n",
        "le = LabelEncoder()\n",
        "new_labels = le.fit_transform(med_data['labels'])\n",
        "class_names = le.classes_\n",
        "\n",
        "label_mapping = {class_name: index for index, class_name in enumerate(class_names)}\n",
        "print(label_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd4sGU4iPoMs",
        "outputId": "7b4f875f-36af-48e5-e8b5-20182147ad45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Nasal Congestion': 0, 'alzheimers': 1, 'back pain': 2, 'chest pain': 3, 'common cold': 4, 'congestion': 5, 'cough': 6, 'depression': 7, 'diabetes': 8, 'diarhea': 9, 'diarrhea': 10, 'fever': 11, 'gastrointestinal': 12, 'gastrointestinal and respiratory': 13, 'headache': 14, 'heart attack': 15, 'rash': 16, 'urinary tract infection': 17, 'weakness': 18}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMWithAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # Multiplying by 2 because we have bidirectional LSTM\n",
        "\n",
        "    def attention(self, lstm_output, final_state):\n",
        "        hidden = final_state.view(-1, self.hidden_size*2, 1)  # Reshape final_state for attention calculation\n",
        "        attention_weights = torch.bmm(lstm_output, hidden).squeeze(2)\n",
        "        soft_attention_weights = F.softmax(attention_weights, dim=1).unsqueeze(2)\n",
        "        attention_output = torch.bmm(lstm_output.permute(0,2,1), soft_attention_weights).squeeze(2)\n",
        "        return attention_output.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        embedded = self.embedding(x)\n",
        "        embedded = embedded.to(device)\n",
        "        lstm_out, (hn, cn) = self.lstm(embedded)\n",
        "        attention_out = self.attention(lstm_out, hn[-2:])\n",
        "        output = self.fc(attention_out)\n",
        "        return output.to(device)"
      ],
      "metadata": {
        "id": "IaOjyu08QgNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_w_attn_path = '/content/gdrive/MyDrive/healthbot/LSTMwA/lstm_w_attn_full_final.pt'\n",
        "tokenizer_path = '/content/gdrive/MyDrive/healthbot/LSTMwA/'\n",
        "\n",
        "if device != 'cuda':\n",
        "  lstm_w_attn = torch.load(lstm_w_attn_path,map_location=torch.device('cpu'))\n",
        "else:\n",
        "  stm_w_attn = torch.load(lstm_w_attn_path)\n",
        "\n",
        "lstm_tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "lstm_w_attn = lstm_w_attn.to(device)\n",
        "lstm_w_attn.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX3tZNrJOS3w",
        "outputId": "5621f455-a56f-4869-90e8-6333d7b8acc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMWithAttention(\n",
              "  (embedding): Embedding(30522, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum length of the sequences\n",
        "def ic_preprocess(preprocessed_txts, lbls):\n",
        "  # Tokenize and encode the text data\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  max_length = 0\n",
        "  for text in preprocessed_txts:\n",
        "    encoded_dict = tokenizer(text, add_special_tokens=True, return_tensors='pt')\n",
        "    input_id = encoded_dict['input_ids']\n",
        "    attention_mask = encoded_dict['attention_mask']\n",
        "    input_ids.append(input_id)\n",
        "    attention_masks.append(attention_mask)\n",
        "    max_length = max(max_length, input_id.shape[1])\n",
        "\n",
        "# Pad the sequences\n",
        "  for i in range(len(input_ids)):\n",
        "    input_ids[i] = torch.cat([input_ids[i], torch.zeros(1, max_length - input_ids[i].shape[1]).long()], dim=1)\n",
        "    attention_masks[i] = torch.cat([attention_masks[i], torch.zeros(1, max_length - attention_masks[i].shape[1]).long()], dim=1)\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
        "  if lbls is not None:\n",
        "    labels = torch.tensor(lbls).to(device)\n",
        "    return input_ids, attention_masks, labels\n",
        "\n",
        "  else:\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "gQV2GFSwO3yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_for_lstm(text):\n",
        "  text = [text]\n",
        "  prepro_txts = preprocess(text)\n",
        "  ip_ids, attn_mask = ic_preprocess(prepro_txts, lbls=None)\n",
        "  ip_ids = ip_ids.to(device)\n",
        "  attn_mask = attn_mask.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = lstm_w_attn(ip_ids)#, attention_mask=attn_mask)\n",
        "    _, predicts = torch.max(outputs.data, 1)\n",
        "\n",
        "  inverted_label_dict = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "  if isinstance(predicts, torch.Tensor):\n",
        "    predicts = predicts.cpu().numpy()  # If predicts is a tensor\n",
        "  predicts = [int(label) for label in predicts]  # Convert to int if they are numpy types or Python tensors\n",
        "\n",
        "  # Map the predicted labels to string labels\n",
        "  diseases = [inverted_label_dict[label] for label in predicts]\n",
        "  return diseases[0]"
      ],
      "metadata": {
        "id": "5rYFGeFAOTyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_model_path = '/content/gdrive/MyDrive/healthbot/gpt2-new'\n",
        "# Load your fine-tuned GPT-2 model and tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(gpt2_model_path, output_hidden_states=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUGdRWMYpLGY",
        "outputId": "f7e0e8f9-f372-4d90-9b9c-62fd003c8ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50258, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(model, tokenizer, prompt, max_length=300):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "    # Adjusting generation parameters\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        temperature=2.0,  # Adjust for randomness\n",
        "        top_p=0.9,        # Nucleus sampling\n",
        "        no_repeat_ngram_size=2,  # Prevent repeating n-grams\n",
        "        early_stopping=True,\n",
        "        do_sample=True,\n",
        "        num_beams=2\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Optionally, remove the prompt from the output\n",
        "    if generated_text.startswith(prompt):\n",
        "        generated_text = generated_text[len(prompt):].strip()\n",
        "\n",
        "    greeting = \"Here's what I found for you:\\n\"\n",
        "    return greeting + generated_text"
      ],
      "metadata": {
        "id": "aLCvoGYUpLD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(inp_text, disease, knowledge_graph):\n",
        "    start_prompt = f\"For the context of {disease}, please consider the symptom and medicine information below:\\n\\n\"\n",
        "\n",
        "    # Include symptom and medicine information from the knowledge graph\n",
        "    symptom_info = \"\\n\".join([f\"- {symptom}\" for symptom in knowledge_graph[disease]['symptoms']])\n",
        "    medicine_info = \"\\n\".join([f\"- {medicine}\" for medicine in knowledge_graph[disease]['medicines']])\n",
        "\n",
        "    prompt = start_prompt + f\"Symptoms for {disease}:\\n{symptom_info}\\n\\nMedicines for {disease}:\\n{medicine_info}\\n\\n\" + inp_text\n",
        "\n",
        "    # Instruct the model to answer the question\n",
        "    prompt += \"\\n\\nPlease provide an answer to the following question:\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "riJfu1fjRYxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUCe7m0qpHf8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from nltk.chat.util import Chat, reflections\n",
        "\n",
        "\n",
        "#model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Pairs is a list of patterns and responses.\n",
        "pairs = [\n",
        "    [\n",
        "        r\"hi|hello|hey\",\n",
        "        [\"Hello, I'm HealthBot. How can I assist you today?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"what are the symptoms of (.*)\",\n",
        "        [\"The symptoms of %1 include...\", \"Symptoms of %1 can range from...\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"how to treat (.*)\",\n",
        "        [\"Treatment for %1 includes...\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"what is (.*) used for\",\n",
        "        [\"%1 is used to treat...\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"quit\",\n",
        "        [\"Goodbye! If you have more questions in the future, don't hesitate to ask.\",]\n",
        "    ],\n",
        "]\n",
        "\n",
        "# This is a simple reflection function that can be used to flip a few pronouns\n",
        "# e.g. 'I am' becomes 'you are'\n",
        "reflections = {\n",
        "    \"i am\": \"you are\",\n",
        "    \"i was\": \"you were\",\n",
        "    \"i\": \"you\",\n",
        "    \"i'm\": \"you are\",\n",
        "    \"i'd\": \"you would\",\n",
        "    \"i've\": \"you have\",\n",
        "    \"i'll\": \"you will\",\n",
        "    \"my\": \"your\",\n",
        "    \"you are\": \"I am\",\n",
        "    \"you were\": \"I was\",\n",
        "    \"you've\": \"I have\",\n",
        "    \"you'll\": \"I will\",\n",
        "    \"your\": \"my\",\n",
        "    \"yours\": \"mine\",\n",
        "    \"you\": \"me\",\n",
        "    \"me\": \"you\"\n",
        "}\n",
        "\n",
        "# Create your own Chatbot\n",
        "health_bot = Chat(pairs, reflections)\n",
        "\n",
        "def health_bot_chat():\n",
        "    print(\"HealthBot\\n---------\")\n",
        "    print(\"Hello! I'm HealthBot. I can help you with general health questions.\\nType 'quit' to leave the chat.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"HealthBot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        disease = preprocess_for_lstm(user_input)\n",
        "        new_input = generate_prompt(user_input, disease, knowledge_graph)\n",
        "        # Generate a response using your GPT-2 model\n",
        "        response = generate_answer(model,tokenizer,new_input)\n",
        "        print(\"HealthBot:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health_bot_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT65xD7Spn33",
        "outputId": "a4431ed8-e290-4169-9f40-32f88e03a18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HealthBot\n",
            "---------\n",
            "Hello! I'm HealthBot. I can help you with general health questions.\n",
            "Type 'quit' to leave the chat.\n",
            "You: What are the medicines of diabetes?\n",
            "HealthBot: Here's what I found for you:\n",
            "The medicines for diabetes include: Fiber-containing foods, Antiplatelet medications, Lifestyle changes, Dietary modifications, and Dietary changes. medicines include, Fiber, Antioxidants, Vitamin C supplements, Sulfonylureas, Calcium channel blockers, Bismuth subsalicylate supplements.\n",
            "You: What are the symptoms of UTI?\n",
            "HealthBot: Here's what I found for you:\n",
            "The symptoms associated with UTIs include: Abruption of bowel movement, Gas, Vibration, Heart attack, Abrupt bowel movements. medicines for urinary tract infection include H. pylori, Antipyretic medications, Antiplatelet medications. The medicines include antihistamines, Prolonged urination, Pain relievers for underlying causes, and Antiinflammatory medications for specific causes.The medicines are safe for use in adults and children. It's important to consult a healthcare provider for proper evaluation and diagnosis.\n",
            "How can I tell if someone is suffering from gastrointestinal issues?\n",
            "You: quit\n",
            "HealthBot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health_bot_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo-WwOBYpn1l",
        "outputId": "91e8b417-c511-4ba4-fd68-c2ee9162da97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HealthBot\n",
            "---------\n",
            "Hello! I'm HealthBot. I can help you with general health questions.\n",
            "Type 'quit' to leave the chat.\n",
            "You: What are the medicines of diabetes?\n",
            "HealthBot: Here's what I found for you:\n",
            "The medicines for diabetes include: Oral antidiabetic drugs, Insulin, TENS therapy, Fiber supplement, Vitamin C supplements, Thrombolytics, Beta-blockers (TENS inhibitors). medicines include Antipyretic medications, Lifestyle changes to manage lifestyle changes, Dietary modifications, Antihistamines, Preventive medications.\n",
            "You: What are the symptoms of UTI?\n",
            "HealthBot: Here's what I found for you:\n",
            "The symptoms associated with UTIs include: Gas, Chills, Constitation, Blood or mucus-filled sores, Heart attack, Diplopia, Hunger, and Urgent need to have a bowel movement evaluation. medicines for UTi include H. pylori, Antiviral medications, Antiplatelet medications. This may suggest preventive options to help alleviate symptoms like heartburn, ulcers or other gastrointestinal symptoms. It may be necessary to seek medical attention for serious underlying causes, such as multiple sclerosis or severe cases of COPD-like conditions.\n",
            "You: quit\n",
            "HealthBot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQ3tDd3bTQ2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvhtiKWlTQ0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}